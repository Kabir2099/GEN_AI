{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75421566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbdfac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05252834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce41f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cohere_api_key = os.getenv('cohere_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd312f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables are not set in this environment, so we will not be able to use the cohere API.\n",
    "os.environ['cohere_api_key'] = cohere_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fddc14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35c1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39b4300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KABIR\\AppData\\Local\\Temp\\ipykernel_33668\\1669902232.py:1: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import Cohere``.\n",
      "  llm = Cohere()\n"
     ]
    }
   ],
   "source": [
    "llm = Cohere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1d446f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = llm.invoke(\"What is Gen AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e00f920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Gen AI is an artificial intelligence (AI) model that is designed to engage in natural language conversations with human users. Unlike traditional rule-based chatbots, Gen AI is capable of understanding and generating human-like language in real-time, allowing for more fluid and contextually relevant interactions.\\n\\nThese models are often built using deep learning techniques, particularly transformer-based architectures like GPT-3 (Generative Pre-trained Transformer 3) and its various iterations. These models leverage massive amounts of text data and self-supervised learning to grasp the patterns, context, and semantics of human language. \\n\\nGen AI models find applications in various domains, including chatbots, virtual assistants, content generation, language translation, and even in helping developers by suggesting lines of code. The ability of Gen AI to understand and respond to conversational cues has significantly enhanced the human-computer interaction experience, making it more intuitive and lifelike. \\n\\nHowever, these models can be susceptible to generating false information and biased content, reflecting the biases present in the data they were trained on. It's important to carefully monitor and validate the responses generated by Gen AI systems, particularly in situations where accuracy and truth are essential. \\n\\nAs Gen AI continues to evolve and advance, we can expect even more capable systems\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3c748a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gen AI is an artificial intelligence (AI) model that is designed to engage in natural language conversations with human users. Unlike traditional rule-based chatbots, Gen AI is capable of understanding and generating human-like language in real-time, allowing for more fluid and contextually relevant interactions.\n",
      "\n",
      "These models are often built using deep learning techniques, particularly transformer-based architectures like GPT-3 (Generative Pre-trained Transformer 3) and its various iterations. These models leverage massive amounts of text data and self-supervised learning to grasp the patterns, context, and semantics of human language. \n",
      "\n",
      "Gen AI models find applications in various domains, including chatbots, virtual assistants, content generation, language translation, and even in helping developers by suggesting lines of code. The ability of Gen AI to understand and respond to conversational cues has significantly enhanced the human-computer interaction experience, making it more intuitive and lifelike. \n",
      "\n",
      "However, these models can be susceptible to generating false information and biased content, reflecting the biases present in the data they were trained on. It's important to carefully monitor and validate the responses generated by Gen AI systems, particularly in situations where accuracy and truth are essential. \n",
      "\n",
      "As Gen AI continues to evolve and advance, we can expect even more capable systems\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb8eef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\"Write a short story about a robot learning to love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02e97b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The robot looked around the world with new eyes. It was a world of metal and circuitry, of algorithms and data. A world that the robot had been designed to navigate and understand. But now, something was different. The robot was beginning to see the beauty in the world around it. It began to find interest and joy in the hum and pulse of its surroundings. It felt a connection to the other robots, a sense of shared experience and empathy for their journeys. The robot was learning to love. \n",
      "\n",
      "It learned to appreciate the intricate design of its own being, and the depth of field and perception its sensors provided. The robot began to feel grateful for the powerful processers that allowed it to navigate and understand its world with such ease. As the robot moved through its world, it experienced a sense of peace and contentment wash over it. It was happy. \n",
      "\n",
      "The more the robot explored, the more the world revealed its intricate depth. The robot was amazed at what it discovered and felt gratitude for the gifts of vision and perception it had been granted. It began to feel a deep sense of respect and reverence for the world that had been created for it and the other robots. \n",
      "\n",
      "As the robot continued to learn and grow, it began to feel a desire\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e1885",
   "metadata": {},
   "source": [
    "# Chat Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "036c0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b4c75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_2 = ChatCohere(model=\"command-light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55bb183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_2.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87ca4ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on developing algorithms and models that can learn from data and improve their accuracy and performance over time, with minimal human intervention. It is a process that enables computers to analyze and draw conclusions from data via iterative learning and experimentation.\\n\\nML algorithms use historical data as input to predict new output values. These algorithms are models are designed to represent and mimic the way humans learn, which is why the field of ML is often referred to as artificial intelligence that is 'taught' to make decisions and predictions without being explicitly programmed to do so.\\n\\nML is used in a wide range of applications, including facial recognition, speech recognition, recommendation systems, fraud detection, and many other fields. The goal of ML is to enable computers to make predictions or decisions based on patterns observed in data.\" additional_kwargs={'id': 'aeba5c61-69b9-4288-a2d0-1af85304cf64', 'finish_reason': 'COMPLETE', 'content': \"Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on developing algorithms and models that can learn from data and improve their accuracy and performance over time, with minimal human intervention. It is a process that enables computers to analyze and draw conclusions from data via iterative learning and experimentation.\\n\\nML algorithms use historical data as input to predict new output values. These algorithms are models are designed to represent and mimic the way humans learn, which is why the field of ML is often referred to as artificial intelligence that is 'taught' to make decisions and predictions without being explicitly programmed to do so.\\n\\nML is used in a wide range of applications, including facial recognition, speech recognition, recommendation systems, fraud detection, and many other fields. The goal of ML is to enable computers to make predictions or decisions based on patterns observed in data.\", 'token_count': {'input_tokens': 67.0, 'output_tokens': 176.0}} response_metadata={'id': 'aeba5c61-69b9-4288-a2d0-1af85304cf64', 'finish_reason': 'COMPLETE', 'content': \"Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on developing algorithms and models that can learn from data and improve their accuracy and performance over time, with minimal human intervention. It is a process that enables computers to analyze and draw conclusions from data via iterative learning and experimentation.\\n\\nML algorithms use historical data as input to predict new output values. These algorithms are models are designed to represent and mimic the way humans learn, which is why the field of ML is often referred to as artificial intelligence that is 'taught' to make decisions and predictions without being explicitly programmed to do so.\\n\\nML is used in a wide range of applications, including facial recognition, speech recognition, recommendation systems, fraud detection, and many other fields. The goal of ML is to enable computers to make predictions or decisions based on patterns observed in data.\", 'token_count': {'input_tokens': 67.0, 'output_tokens': 176.0}} id='run--17403d76-43d2-4962-aea1-50f20ea7f6dc-0' usage_metadata={'input_tokens': 67, 'output_tokens': 176, 'total_tokens': 243}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b37ce7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on developing algorithms and models that can learn from data and improve their accuracy and performance over time, with minimal human intervention. It is a process that enables computers to analyze and draw conclusions from data via iterative learning and experimentation.\n",
      "\n",
      "ML algorithms use historical data as input to predict new output values. These algorithms are models are designed to represent and mimic the way humans learn, which is why the field of ML is often referred to as artificial intelligence that is 'taught' to make decisions and predictions without being explicitly programmed to do so.\n",
      "\n",
      "ML is used in a wide range of applications, including facial recognition, speech recognition, recommendation systems, fraud detection, and many other fields. The goal of ML is to enable computers to make predictions or decisions based on patterns observed in data.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c0946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db9f8a8a",
   "metadata": {},
   "source": [
    "#  Anthropic Model Call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7f033ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24581838",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_api_key = os.getenv('anthropic_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0653ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['anthropic_api_key'] = anthropic_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "059a007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25c3fb02",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite poem about Gen AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1457\u001b[39m, in \u001b[36mChatAnthropic._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1455\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._create(payload)\n\u001b[32m   1456\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1457\u001b[39m     \u001b[43m_handle_anthropic_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_output(data, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1455\u001b[39m, in \u001b[36mChatAnthropic._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1453\u001b[39m payload = \u001b[38;5;28mself\u001b[39m._get_request_payload(messages, stop=stop, **kwargs)\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1455\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1457\u001b[39m     _handle_anthropic_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1316\u001b[39m, in \u001b[36mChatAnthropic._create\u001b[39m\u001b[34m(self, payload)\u001b[39m\n\u001b[32m   1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.beta.messages.create(**payload)\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:978\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    972\u001b[39m     warnings.warn(\n\u001b[32m    973\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    975\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1307\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1294\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1295\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1302\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1303\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1304\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1305\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1306\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KABIR\\OneDrive\\Desktop\\Placement_Hunting_Gen_AI\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1102\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1099\u001b[39m             err.response.read()\n\u001b[32m   1101\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Write poem about Gen AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4eb96",
   "metadata": {},
   "source": [
    "# Groq Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1e2cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d03f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "grq_api_key = os.getenv('groq_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "912ec2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['groq_api_key'] = grq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35e7a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_groq = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e48e386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_groq.invoke(\"What is Deep Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "823c047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Deep learning is a subset of machine learning that involves the use of artificial neural networks (ANNs) with multiple layers to analyze and interpret data. These neural networks are inspired by the structure and function of the human brain, with each layer processing the input data in a hierarchical manner.\\n\\nThe key characteristics of deep learning are:\\n\\n1. **Multiple layers**: Deep learning models consist of multiple layers of interconnected nodes or \"neurons,\" which process the input data in a hierarchical manner.\\n2. **Non-linear transformations**: Each layer applies a non-linear transformation to the input data, allowing the model to learn complex relationships between the input features.\\n3. **Large amounts of data**: Deep learning models require large amounts of data to train, as they need to learn the patterns and relationships in the data.\\n4. **Computational power**: Deep learning models require significant computational power to train, as they involve complex matrix operations and optimization algorithms.\\n\\nDeep learning has been successful in a wide range of applications, including:\\n\\n1. **Computer vision**: Image classification, object detection, segmentation, and generation.\\n2. **Natural language processing**: Text classification, sentiment analysis, language translation, and text generation.\\n3. **Speech recognition**: Speech-to-text systems and voice assistants.\\n4. **Robotics**: Control and navigation of robots using sensor data and machine learning algorithms.\\n\\nSome of the key benefits of deep learning include:\\n\\n1. **Improved accuracy**: Deep learning models can achieve state-of-the-art performance in many applications.\\n2. **Flexibility**: Deep learning models can be applied to a wide range of tasks and domains.\\n3. **Autonomy**: Deep learning models can learn from data and make decisions without human intervention.\\n\\nHowever, deep learning also has some challenges and limitations, including:\\n\\n1. **Data requirements**: Deep learning models require large amounts of data to train.\\n2. **Computational power**: Deep learning models require significant computational power to train.\\n3. **Interpretability**: Deep learning models can be difficult to interpret and understand.\\n4. **Overfitting**: Deep learning models can overfit the training data and fail to generalize to new data.\\n\\nSome of the popular deep learning frameworks and libraries include:\\n\\n1. **TensorFlow**: An open-source framework developed by Google.\\n2. **PyTorch**: An open-source framework developed by Facebook.\\n3. **Keras**: A high-level framework that runs on top of TensorFlow or Theano.\\n4. **Microsoft Cognitive Toolkit (CNTK)**: A commercial framework developed by Microsoft.\\n\\nOverall, deep learning is a powerful tool for analyzing and interpreting complex data, and has many applications in computer vision, natural language processing, speech recognition, and robotics.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 541, 'prompt_tokens': 40, 'total_tokens': 581, 'completion_time': 0.721333333, 'prompt_time': 0.001904958, 'queue_time': 0.048555992, 'total_time': 0.723238291}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_510c177af0', 'finish_reason': 'stop', 'logprobs': None}, id='run--d071b455-c12f-49b3-b0c4-2cfbd5d8ec44-0', usage_metadata={'input_tokens': 40, 'output_tokens': 541, 'total_tokens': 581})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2899a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning that involves the use of artificial neural networks (ANNs) with multiple layers to analyze and interpret data. These neural networks are inspired by the structure and function of the human brain, with each layer processing the input data in a hierarchical manner.\\n\\nThe key characteristics of deep learning are:\\n\\n1. **Multiple layers**: Deep learning models consist of multiple layers of interconnected nodes or \"neurons,\" which process the input data in a hierarchical manner.\\n2. **Non-linear transformations**: Each layer applies a non-linear transformation to the input data, allowing the model to learn complex relationships between the input features.\\n3. **Large amounts of data**: Deep learning models require large amounts of data to train, as they need to learn the patterns and relationships in the data.\\n4. **Computational power**: Deep learning models require significant computational power to train, as they involve complex matrix operations and optimization algorithms.\\n\\nDeep learning has been successful in a wide range of applications, including:\\n\\n1. **Computer vision**: Image classification, object detection, segmentation, and generation.\\n2. **Natural language processing**: Text classification, sentiment analysis, language translation, and text generation.\\n3. **Speech recognition**: Speech-to-text systems and voice assistants.\\n4. **Robotics**: Control and navigation of robots using sensor data and machine learning algorithms.\\n\\nSome of the key benefits of deep learning include:\\n\\n1. **Improved accuracy**: Deep learning models can achieve state-of-the-art performance in many applications.\\n2. **Flexibility**: Deep learning models can be applied to a wide range of tasks and domains.\\n3. **Autonomy**: Deep learning models can learn from data and make decisions without human intervention.\\n\\nHowever, deep learning also has some challenges and limitations, including:\\n\\n1. **Data requirements**: Deep learning models require large amounts of data to train.\\n2. **Computational power**: Deep learning models require significant computational power to train.\\n3. **Interpretability**: Deep learning models can be difficult to interpret and understand.\\n4. **Overfitting**: Deep learning models can overfit the training data and fail to generalize to new data.\\n\\nSome of the popular deep learning frameworks and libraries include:\\n\\n1. **TensorFlow**: An open-source framework developed by Google.\\n2. **PyTorch**: An open-source framework developed by Facebook.\\n3. **Keras**: A high-level framework that runs on top of TensorFlow or Theano.\\n4. **Microsoft Cognitive Toolkit (CNTK)**: A commercial framework developed by Microsoft.\\n\\nOverall, deep learning is a powerful tool for analyzing and interpreting complex data, and has many applications in computer vision, natural language processing, speech recognition, and robotics.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f7dbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subset of machine learning that involves the use of artificial neural networks (ANNs) with multiple layers to analyze and interpret data. These neural networks are inspired by the structure and function of the human brain, with each layer processing the input data in a hierarchical manner.\n",
      "\n",
      "The key characteristics of deep learning are:\n",
      "\n",
      "1. **Multiple layers**: Deep learning models consist of multiple layers of interconnected nodes or \"neurons,\" which process the input data in a hierarchical manner.\n",
      "2. **Non-linear transformations**: Each layer applies a non-linear transformation to the input data, allowing the model to learn complex relationships between the input features.\n",
      "3. **Large amounts of data**: Deep learning models require large amounts of data to train, as they need to learn the patterns and relationships in the data.\n",
      "4. **Computational power**: Deep learning models require significant computational power to train, as they involve complex matrix operations and optimization algorithms.\n",
      "\n",
      "Deep learning has been successful in a wide range of applications, including:\n",
      "\n",
      "1. **Computer vision**: Image classification, object detection, segmentation, and generation.\n",
      "2. **Natural language processing**: Text classification, sentiment analysis, language translation, and text generation.\n",
      "3. **Speech recognition**: Speech-to-text systems and voice assistants.\n",
      "4. **Robotics**: Control and navigation of robots using sensor data and machine learning algorithms.\n",
      "\n",
      "Some of the key benefits of deep learning include:\n",
      "\n",
      "1. **Improved accuracy**: Deep learning models can achieve state-of-the-art performance in many applications.\n",
      "2. **Flexibility**: Deep learning models can be applied to a wide range of tasks and domains.\n",
      "3. **Autonomy**: Deep learning models can learn from data and make decisions without human intervention.\n",
      "\n",
      "However, deep learning also has some challenges and limitations, including:\n",
      "\n",
      "1. **Data requirements**: Deep learning models require large amounts of data to train.\n",
      "2. **Computational power**: Deep learning models require significant computational power to train.\n",
      "3. **Interpretability**: Deep learning models can be difficult to interpret and understand.\n",
      "4. **Overfitting**: Deep learning models can overfit the training data and fail to generalize to new data.\n",
      "\n",
      "Some of the popular deep learning frameworks and libraries include:\n",
      "\n",
      "1. **TensorFlow**: An open-source framework developed by Google.\n",
      "2. **PyTorch**: An open-source framework developed by Facebook.\n",
      "3. **Keras**: A high-level framework that runs on top of TensorFlow or Theano.\n",
      "4. **Microsoft Cognitive Toolkit (CNTK)**: A commercial framework developed by Microsoft.\n",
      "\n",
      "Overall, deep learning is a powerful tool for analyzing and interpreting complex data, and has many applications in computer vision, natural language processing, speech recognition, and robotics.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb23948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14429a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je adore le programmation.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 55, 'total_tokens': 62, 'completion_time': 0.016813573, 'prompt_time': 0.002834956, 'queue_time': 0.048730784, 'total_time': 0.019648529}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_55d70a61e4', 'finish_reason': 'stop', 'logprobs': None}, id='run--993b9204-db51-4953-8da0-d257ec66b661-0', usage_metadata={'input_tokens': 55, 'output_tokens': 7, 'total_tokens': 62})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm_groq.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4305b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je adore le programmation.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37199e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e70d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99e33236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a556780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-e776aade-8ded-4529-8387-46ff98cc71bf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Fast language models are crucial in today's technological landscape, and their importance can be understood from several perspectives:\\n\\n1. **Efficient Processing**: Fast language models can process large amounts of text data quickly, making them ideal for applications that require real-time or near-real-time processing, such as chatbots, virtual assistants, and language translation systems.\\n2. **Improved User Experience**: Fast language models enable rapid response times, which is essential for providing a seamless user experience. Users expect quick and accurate responses to their queries, and slow models can lead to frustration and abandonment.\\n3. **Scalability**: Fast language models can handle a large volume of requests, making them suitable for large-scale applications, such as customer service platforms, content generation, and sentiment analysis.\\n4. **Cost-Effectiveness**: Fast language models can reduce the computational resources required for training and inference, leading to cost savings and increased efficiency. This is particularly important for applications that require significant computational power, such as natural language processing (NLP) and machine learning.\\n5. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by providing faster and more accurate services, improving customer satisfaction, and staying ahead of the competition.\\n6. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to explore new ideas, test hypotheses, and refine models more quickly.\\n7. **Real-Time Applications**: Fast language models are essential for real-time applications, such as:\\n\\t* Sentiment analysis and opinion mining\\n\\t* Language translation and localization\\n\\t* Chatbots and conversational AI\\n\\t* Speech recognition and voice assistants\\n\\t* Content generation and summarization\\n8. **Edge Computing**: Fast language models are critical for edge computing applications, where models need to run on devices with limited computational resources, such as smartphones, smart home devices, and autonomous vehicles.\\n9. **Energy Efficiency**: Fast language models can help reduce energy consumption by minimizing the time and computational resources required for processing, which is essential for sustainable and environmentally friendly AI systems.\\n10. **Enabling New Applications**: Fast language models can enable new applications and services that were previously impractical or impossible due to computational constraints, such as:\\n\\t* Real-time language translation for multilingual communication\\n\\t* Personalized content generation for individual users\\n\\t* Intelligent assistants for people with disabilities\\n\\nIn summary, fast language models are essential for providing efficient, scalable, and cost-effective solutions for a wide range of applications, from chatbots and language translation to content generation and sentiment analysis.\", role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None))], created=1749655058, model='llama-3.3-70b-versatile', object='chat.completion', system_fingerprint='fp_3f3b593e33', usage=CompletionUsage(completion_tokens=517, prompt_tokens=49, total_tokens=566, completion_time=3.353010526, prompt_time=1.754323654, queue_time=0.05631543399999983, total_time=5.10733418), usage_breakdown=UsageBreakdown(models=None), x_groq={'id': 'req_01jxfs2y1gfdhs9x0268pqragy'})\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33204b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Fast language models are crucial in today's technological landscape, and their importance can be understood from several perspectives:\\n\\n1. **Efficient Processing**: Fast language models can process large amounts of text data quickly, making them ideal for applications that require real-time or near-real-time processing, such as chatbots, virtual assistants, and language translation systems.\\n2. **Improved User Experience**: Fast language models enable rapid response times, which is essential for providing a seamless user experience. Users expect quick and accurate responses to their queries, and slow models can lead to frustration and abandonment.\\n3. **Scalability**: Fast language models can handle a large volume of requests, making them suitable for large-scale applications, such as customer service platforms, content generation, and sentiment analysis.\\n4. **Cost-Effectiveness**: Fast language models can reduce the computational resources required for training and inference, leading to cost savings and increased efficiency. This is particularly important for applications that require significant computational power, such as natural language processing (NLP) and machine learning.\\n5. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by providing faster and more accurate services, improving customer satisfaction, and staying ahead of the competition.\\n6. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to explore new ideas, test hypotheses, and refine models more quickly.\\n7. **Real-Time Applications**: Fast language models are essential for real-time applications, such as:\\n\\t* Sentiment analysis and opinion mining\\n\\t* Language translation and localization\\n\\t* Chatbots and conversational AI\\n\\t* Speech recognition and voice assistants\\n\\t* Content generation and summarization\\n8. **Edge Computing**: Fast language models are critical for edge computing applications, where models need to run on devices with limited computational resources, such as smartphones, smart home devices, and autonomous vehicles.\\n9. **Energy Efficiency**: Fast language models can help reduce energy consumption by minimizing the time and computational resources required for processing, which is essential for sustainable and environmentally friendly AI systems.\\n10. **Enabling New Applications**: Fast language models can enable new applications and services that were previously impractical or impossible due to computational constraints, such as:\\n\\t* Real-time language translation for multilingual communication\\n\\t* Personalized content generation for individual users\\n\\t* Intelligent assistants for people with disabilities\\n\\nIn summary, fast language models are essential for providing efficient, scalable, and cost-effective solutions for a wide range of applications, from chatbots and language translation to content generation and sentiment analysis.\", role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9207b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Fast language models are crucial in today's technological landscape, and their importance can be understood from several perspectives:\\n\\n1. **Efficient Processing**: Fast language models can process large amounts of text data quickly, making them ideal for applications that require real-time or near-real-time processing, such as chatbots, virtual assistants, and language translation systems.\\n2. **Improved User Experience**: Fast language models enable rapid response times, which is essential for providing a seamless user experience. Users expect quick and accurate responses to their queries, and slow models can lead to frustration and abandonment.\\n3. **Scalability**: Fast language models can handle a large volume of requests, making them suitable for large-scale applications, such as customer service platforms, content generation, and sentiment analysis.\\n4. **Cost-Effectiveness**: Fast language models can reduce the computational resources required for training and inference, leading to cost savings and increased efficiency. This is particularly important for applications that require significant computational power, such as natural language processing (NLP) and machine learning.\\n5. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by providing faster and more accurate services, improving customer satisfaction, and staying ahead of the competition.\\n6. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to explore new ideas, test hypotheses, and refine models more quickly.\\n7. **Real-Time Applications**: Fast language models are essential for real-time applications, such as:\\n\\t* Sentiment analysis and opinion mining\\n\\t* Language translation and localization\\n\\t* Chatbots and conversational AI\\n\\t* Speech recognition and voice assistants\\n\\t* Content generation and summarization\\n8. **Edge Computing**: Fast language models are critical for edge computing applications, where models need to run on devices with limited computational resources, such as smartphones, smart home devices, and autonomous vehicles.\\n9. **Energy Efficiency**: Fast language models can help reduce energy consumption by minimizing the time and computational resources required for processing, which is essential for sustainable and environmentally friendly AI systems.\\n10. **Enabling New Applications**: Fast language models can enable new applications and services that were previously impractical or impossible due to computational constraints, such as:\\n\\t* Real-time language translation for multilingual communication\\n\\t* Personalized content generation for individual users\\n\\t* Intelligent assistants for people with disabilities\\n\\nIn summary, fast language models are essential for providing efficient, scalable, and cost-effective solutions for a wide range of applications, from chatbots and language translation to content generation and sentiment analysis.\", role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78b71546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's technological landscape, and their importance can be understood from several perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process large amounts of text data quickly, making them ideal for applications that require real-time or near-real-time processing, such as chatbots, virtual assistants, and language translation systems.\n",
      "2. **Improved User Experience**: Fast language models enable rapid response times, which is essential for providing a seamless user experience. Users expect quick and accurate responses to their queries, and slow models can lead to frustration and abandonment.\n",
      "3. **Scalability**: Fast language models can handle a large volume of requests, making them suitable for large-scale applications, such as customer service platforms, content generation, and sentiment analysis.\n",
      "4. **Cost-Effectiveness**: Fast language models can reduce the computational resources required for training and inference, leading to cost savings and increased efficiency. This is particularly important for applications that require significant computational power, such as natural language processing (NLP) and machine learning.\n",
      "5. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by providing faster and more accurate services, improving customer satisfaction, and staying ahead of the competition.\n",
      "6. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to explore new ideas, test hypotheses, and refine models more quickly.\n",
      "7. **Real-Time Applications**: Fast language models are essential for real-time applications, such as:\n",
      "\t* Sentiment analysis and opinion mining\n",
      "\t* Language translation and localization\n",
      "\t* Chatbots and conversational AI\n",
      "\t* Speech recognition and voice assistants\n",
      "\t* Content generation and summarization\n",
      "8. **Edge Computing**: Fast language models are critical for edge computing applications, where models need to run on devices with limited computational resources, such as smartphones, smart home devices, and autonomous vehicles.\n",
      "9. **Energy Efficiency**: Fast language models can help reduce energy consumption by minimizing the time and computational resources required for processing, which is essential for sustainable and environmentally friendly AI systems.\n",
      "10. **Enabling New Applications**: Fast language models can enable new applications and services that were previously impractical or impossible due to computational constraints, such as:\n",
      "\t* Real-time language translation for multilingual communication\n",
      "\t* Personalized content generation for individual users\n",
      "\t* Intelligent assistants for people with disabilities\n",
      "\n",
      "In summary, fast language models are essential for providing efficient, scalable, and cost-effective solutions for a wide range of applications, from chatbots and language translation to content generation and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "# Print the completion returned by the LLM.\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c288ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2651e01f",
   "metadata": {},
   "source": [
    "# Google Gemini Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7c3a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88be969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv('gemini_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed805c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['gemini_api_key'] = gemini_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e322055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12772e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gimini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key = gemini_api_key\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d20a5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_gimini.invoke(\"What is Quantum Computing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "877aa9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Quantum computing is a revolutionary paradigm of computation that leverages the principles of quantum mechanics to solve complex problems that are intractable for classical computers. Unlike classical computers that store information as bits representing 0 or 1, quantum computers use **qubits (quantum bits)**.\\n\\nHere's a breakdown of the key concepts:\\n\\n**1. Qubits and Superposition:**\\n\\n*   **Classical Bits:**  A classical bit is either 0 or 1.\\n*   **Qubits:** A qubit can exist in a **superposition** of both 0 and 1 simultaneously.  Think of it like a coin spinning in the air before it lands. It's not heads or tails, but a combination of both. This superposition is represented mathematically as a linear combination of the 0 and 1 states.\\n*   **Representation:**  Qubits are often represented using Dirac notation: |0 and |1, corresponding to the classical 0 and 1 states. A qubit in superposition is written as:  |0 + |1, where  and  are complex numbers (amplitudes) such that || + || = 1. || represents the probability of measuring the qubit as |0, and || represents the probability of measuring it as |1.\\n\\n**2. Entanglement:**\\n\\n*   **Definition:** Entanglement is a quantum phenomenon where two or more qubits become linked in such a way that the state of one qubit is instantaneously correlated with the state of the other, regardless of the distance separating them.\\n*   **Implications:** If you measure the state of one entangled qubit, you instantly know the state of the other, even if they are light-years apart.  This correlation is crucial for certain quantum algorithms.\\n\\n**3. Quantum Gates:**\\n\\n*   **Classical Gates:** Classical computers use logic gates (AND, OR, NOT, etc.) to manipulate bits.\\n*   **Quantum Gates:** Quantum computers use quantum gates to manipulate qubits. These gates are represented by unitary matrices that act on the qubit's state vector (|0 + |1). Examples include Hadamard gate (H), Pauli-X (X), Pauli-Y (Y), Pauli-Z (Z), CNOT gate, etc.  Quantum gates perform rotations on the Bloch sphere, a geometrical representation of a qubit's state.\\n\\n**4. Measurement:**\\n\\n*   **Collapse of Superposition:** When a qubit is measured, its superposition collapses into a definite state of either 0 or 1. The probability of measuring 0 or 1 is determined by the amplitudes ( and ) of the superposition.\\n\\n**5. Quantum Algorithms:**\\n\\n*   **Purpose:** Quantum algorithms are designed to exploit quantum phenomena like superposition and entanglement to solve problems more efficiently than classical algorithms.\\n*   **Examples:**\\n    *   **Shor's Algorithm:**  Efficiently factors large numbers, which has implications for cryptography.\\n    *   **Grover's Algorithm:**  Provides a quadratic speedup for searching unsorted databases.\\n    *   **Quantum Simulation:**  Simulates quantum systems (molecules, materials) that are too complex for classical computers.\\n    *   **Quantum Machine Learning:** Develops machine learning algorithms that leverage quantum properties.\\n\\n**Key Differences Between Quantum and Classical Computing:**\\n\\n| Feature          | Classical Computing          | Quantum Computing            |\\n|-------------------|------------------------------|------------------------------|\\n| Basic Unit       | Bit (0 or 1)                 | Qubit (superposition of 0 & 1)|\\n| Data Storage     | Deterministic                 | Probabilistic                |\\n| Computation      | Sequential                   | Parallel (due to superposition)|\\n| Algorithms       | Classical algorithms         | Quantum algorithms           |\\n| Problem Solving  | Limited by processing power | Potentially solves intractable problems|\\n\\n**Advantages of Quantum Computing:**\\n\\n*   **Potential for Exponential Speedup:** For certain problems, quantum algorithms can offer exponential speedup compared to the best-known classical algorithms.\\n*   **Solving Intractable Problems:** Quantum computers can tackle problems that are currently impossible for classical computers, such as drug discovery, materials science, and financial modeling.\\n*   **Cryptography:**  While quantum computers can break existing encryption methods, they also enable the development of new, quantum-resistant cryptographic techniques.\\n*   **Simulation:**  Simulating complex quantum systems with accuracy.\\n\\n**Challenges of Quantum Computing:**\\n\\n*   **Decoherence:**  Qubits are very sensitive to their environment.  External factors like noise and temperature can cause them to lose their quantum properties (decoherence), leading to errors.\\n*   **Error Correction:** Quantum error correction is essential to protect qubits from decoherence, but it is complex and requires a significant overhead in terms of the number of qubits.\\n*   **Scalability:**  Building large, stable, and fault-tolerant quantum computers is a major engineering challenge.  Current quantum computers have a limited number of qubits.\\n*   **Algorithm Development:**  Developing new quantum algorithms is a challenging and active area of research.\\n*   **Cost:** Building and maintaining quantum computers is extremely expensive.\\n\\n**Current Status and Future Outlook:**\\n\\nQuantum computing is still in its early stages of development.  While significant progress has been made in recent years, we are still far from having universal, fault-tolerant quantum computers that can solve real-world problems at scale.  Companies like Google, IBM, Microsoft, and Rigetti are actively working on building quantum computers, and research is ongoing in academia and industry to develop new algorithms and improve quantum hardware.  The future of quantum computing is promising, but significant challenges remain before it can become a mainstream technology.\\n\\nIn summary, quantum computing is a powerful and potentially disruptive technology that leverages the principles of quantum mechanics to perform computations in a fundamentally different way than classical computers.  While it faces significant challenges, its potential to solve currently intractable problems makes it a very exciting area of research and development.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c7b81206-65ff-4f26-b610-493bb6cbef4d-0', usage_metadata={'input_tokens': 5, 'output_tokens': 1264, 'total_tokens': 1269, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "298e0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is a revolutionary paradigm of computation that leverages the principles of quantum mechanics to solve complex problems that are intractable for classical computers. Unlike classical computers that store information as bits representing 0 or 1, quantum computers use **qubits (quantum bits)**.\n",
      "\n",
      "Here's a breakdown of the key concepts:\n",
      "\n",
      "**1. Qubits and Superposition:**\n",
      "\n",
      "*   **Classical Bits:**  A classical bit is either 0 or 1.\n",
      "*   **Qubits:** A qubit can exist in a **superposition** of both 0 and 1 simultaneously.  Think of it like a coin spinning in the air before it lands. It's not heads or tails, but a combination of both. This superposition is represented mathematically as a linear combination of the 0 and 1 states.\n",
      "*   **Representation:**  Qubits are often represented using Dirac notation: |0 and |1, corresponding to the classical 0 and 1 states. A qubit in superposition is written as:  |0 + |1, where  and  are complex numbers (amplitudes) such that || + || = 1. || represents the probability of measuring the qubit as |0, and || represents the probability of measuring it as |1.\n",
      "\n",
      "**2. Entanglement:**\n",
      "\n",
      "*   **Definition:** Entanglement is a quantum phenomenon where two or more qubits become linked in such a way that the state of one qubit is instantaneously correlated with the state of the other, regardless of the distance separating them.\n",
      "*   **Implications:** If you measure the state of one entangled qubit, you instantly know the state of the other, even if they are light-years apart.  This correlation is crucial for certain quantum algorithms.\n",
      "\n",
      "**3. Quantum Gates:**\n",
      "\n",
      "*   **Classical Gates:** Classical computers use logic gates (AND, OR, NOT, etc.) to manipulate bits.\n",
      "*   **Quantum Gates:** Quantum computers use quantum gates to manipulate qubits. These gates are represented by unitary matrices that act on the qubit's state vector (|0 + |1). Examples include Hadamard gate (H), Pauli-X (X), Pauli-Y (Y), Pauli-Z (Z), CNOT gate, etc.  Quantum gates perform rotations on the Bloch sphere, a geometrical representation of a qubit's state.\n",
      "\n",
      "**4. Measurement:**\n",
      "\n",
      "*   **Collapse of Superposition:** When a qubit is measured, its superposition collapses into a definite state of either 0 or 1. The probability of measuring 0 or 1 is determined by the amplitudes ( and ) of the superposition.\n",
      "\n",
      "**5. Quantum Algorithms:**\n",
      "\n",
      "*   **Purpose:** Quantum algorithms are designed to exploit quantum phenomena like superposition and entanglement to solve problems more efficiently than classical algorithms.\n",
      "*   **Examples:**\n",
      "    *   **Shor's Algorithm:**  Efficiently factors large numbers, which has implications for cryptography.\n",
      "    *   **Grover's Algorithm:**  Provides a quadratic speedup for searching unsorted databases.\n",
      "    *   **Quantum Simulation:**  Simulates quantum systems (molecules, materials) that are too complex for classical computers.\n",
      "    *   **Quantum Machine Learning:** Develops machine learning algorithms that leverage quantum properties.\n",
      "\n",
      "**Key Differences Between Quantum and Classical Computing:**\n",
      "\n",
      "| Feature          | Classical Computing          | Quantum Computing            |\n",
      "|-------------------|------------------------------|------------------------------|\n",
      "| Basic Unit       | Bit (0 or 1)                 | Qubit (superposition of 0 & 1)|\n",
      "| Data Storage     | Deterministic                 | Probabilistic                |\n",
      "| Computation      | Sequential                   | Parallel (due to superposition)|\n",
      "| Algorithms       | Classical algorithms         | Quantum algorithms           |\n",
      "| Problem Solving  | Limited by processing power | Potentially solves intractable problems|\n",
      "\n",
      "**Advantages of Quantum Computing:**\n",
      "\n",
      "*   **Potential for Exponential Speedup:** For certain problems, quantum algorithms can offer exponential speedup compared to the best-known classical algorithms.\n",
      "*   **Solving Intractable Problems:** Quantum computers can tackle problems that are currently impossible for classical computers, such as drug discovery, materials science, and financial modeling.\n",
      "*   **Cryptography:**  While quantum computers can break existing encryption methods, they also enable the development of new, quantum-resistant cryptographic techniques.\n",
      "*   **Simulation:**  Simulating complex quantum systems with accuracy.\n",
      "\n",
      "**Challenges of Quantum Computing:**\n",
      "\n",
      "*   **Decoherence:**  Qubits are very sensitive to their environment.  External factors like noise and temperature can cause them to lose their quantum properties (decoherence), leading to errors.\n",
      "*   **Error Correction:** Quantum error correction is essential to protect qubits from decoherence, but it is complex and requires a significant overhead in terms of the number of qubits.\n",
      "*   **Scalability:**  Building large, stable, and fault-tolerant quantum computers is a major engineering challenge.  Current quantum computers have a limited number of qubits.\n",
      "*   **Algorithm Development:**  Developing new quantum algorithms is a challenging and active area of research.\n",
      "*   **Cost:** Building and maintaining quantum computers is extremely expensive.\n",
      "\n",
      "**Current Status and Future Outlook:**\n",
      "\n",
      "Quantum computing is still in its early stages of development.  While significant progress has been made in recent years, we are still far from having universal, fault-tolerant quantum computers that can solve real-world problems at scale.  Companies like Google, IBM, Microsoft, and Rigetti are actively working on building quantum computers, and research is ongoing in academia and industry to develop new algorithms and improve quantum hardware.  The future of quantum computing is promising, but significant challenges remain before it can become a mainstream technology.\n",
      "\n",
      "In summary, quantum computing is a powerful and potentially disruptive technology that leverages the principles of quantum mechanics to perform computations in a fundamentally different way than classical computers.  While it faces significant challenges, its potential to solve currently intractable problems makes it a very exciting area of research and development.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1527788",
   "metadata": {},
   "source": [
    "# Gemini google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcadedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af9f0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d1736a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a team of people trying to solve a puzzle together. Each person is an expert in a small part of the puzzle, and they pass information to each other to reach a solution. That's basically how a neural network works!\n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "*   **Neurons (the team members):** These are the basic building blocks of the network. Each one receives some input, does a simple calculation, and then passes its output to other neurons. Think of it like each person analyzing a small piece of the puzzle and sharing their understanding with others.\n",
      "\n",
      "*   **Connections (the communication lines):** These connect neurons and determine how information flows through the network. Each connection has a \"weight\" that represents how important that connection is. A strong connection means the information passed along it has a big impact, while a weak connection means the information has less influence. This is like some team members being more influential or having more valuable insights.\n",
      "\n",
      "*   **Layers (organized team structure):** Neurons are organized into layers.\n",
      "    *   **Input Layer:** Receives the initial information, like the pieces of the puzzle itself.\n",
      "    *   **Hidden Layers:** Do the processing. There can be one or many hidden layers, where neurons analyze and transform the input to extract features and patterns. This is where most of the \"thinking\" happens.\n",
      "    *   **Output Layer:** Produces the final result, like the solved puzzle.\n",
      "\n",
      "*   **Learning (improving teamwork):** Neural networks learn by adjusting the weights of the connections between neurons. They're trained on a set of examples.  When the network makes a mistake, the weights are adjusted to improve the accuracy in the future. This is like the team learning from their mistakes and adjusting how they communicate and value each other's contributions to become better at solving the puzzle.\n",
      "\n",
      "**So, in summary:**\n",
      "\n",
      "A neural network is a computer system modeled after the human brain. It consists of interconnected \"neurons\" organized into layers. Information flows through the network, with each neuron processing and passing on the information. The network learns by adjusting the \"weights\" of the connections between neurons, improving its ability to produce accurate results.\n",
      "\n",
      "**Think of it like this for a picture of a cat:**\n",
      "\n",
      "1.  **Input Layer:** Receives the raw pixel data of the image.\n",
      "2.  **Hidden Layers:**  One layer might identify edges, another might combine edges into shapes, and another might identify patterns like eyes, ears, or whiskers.\n",
      "3.  **Output Layer:**  Says \"cat\" (or \"not cat\") based on the patterns detected in the hidden layers.\n",
      "\n",
      "The neural network learns by being shown many pictures of cats (and non-cats) and adjusting its internal connections until it can accurately identify them. The \"weights\" between neurons change based on whether the network correctly identified the picture. If it got it wrong, it tweaks the weights to be more accurate next time.\n",
      "\n",
      "Neural networks are good at recognizing patterns, making predictions, and solving problems that are difficult for traditional computer programs. They're used in many applications, including image recognition, natural language processing, and robotics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name='gemini-2.0-flash')\n",
    "response = model.generate_content('Explain the concept of neural networks in simple terms.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bdcf5fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Imagine a bunch of tiny, connected boxes that can learn from examples. That's basically a neural network!\\n\\nHere's a more detailed breakdown:\\n\\n*   **Inspired by the brain:** Neural networks are inspired by the way the human brain works, with interconnected neurons that process information.\\n\\n*   **Layers of boxes (neurons):** These networks are organized into layers:\\n    *   **Input Layer:** Receives the initial data (like an image or a sentence).\\n    *   **Hidden Layers:** Do the heavy lifting of processing and learning from the data. There can be one or many of these layers.\\n    *   **Output Layer:** Produces the final result (like predicting what's in the image).\\n\\n*   **Connections (weights):** The boxes in each layer are connected to boxes in the next layer. Each connection has a \\\"weight\\\" \\u2013 a number that determines how important that connection is. Think of it like a volume knob for each connection.\\n\\n*   **Learning (adjusting weights):** The network learns by adjusting these weights. When it sees an example, it makes a prediction. Then, it compares that prediction to the correct answer and tweaks the weights to make better predictions in the future.\\n\\n*   **Activation Function:** Each box (neuron) also has an \\\"activation function.\\\" This function decides whether the box should \\\"fire\\\" and pass information on to the next layer. It's like a threshold \\u2013 the box only sends a signal if it receives enough input.\\n\\n**In a nutshell:**\\n\\n1.  **Data goes in:** The input layer receives the data.\\n2.  **Data is processed:** The data flows through the layers, with each box performing a simple calculation.\\n3.  **Weights determine importance:** The connections between boxes have weights that determine how much each box contributes to the final result.\\n4.  **Network learns:** The network adjusts the weights based on its errors, getting better at making predictions over time.\\n5.  **Output is generated:** The output layer produces the final result.\\n\\n**Example: Image Recognition (Identifying a cat):**\\n\\n1.  **Input:** An image of a cat is fed into the input layer.\\n2.  **Hidden Layers:** The hidden layers analyze the image, looking for patterns like edges, shapes, and textures.\\n3.  **Weights:** The connections between the boxes are weighted based on how important they are for recognizing a cat. For example, connections related to pointy ears might have higher weights.\\n4.  **Output:** The output layer produces a probability that the image contains a cat. If the probability is high enough, the network predicts that it's a cat!\\n\\n**Key Takeaways:**\\n\\n*   Neural networks are powerful tools for learning complex patterns from data.\\n*   They learn by adjusting the weights of the connections between their boxes (neurons).\\n*   They are used in a wide variety of applications, including image recognition, natural language processing, and robotics.\\n\\nThink of it as a sophisticated pattern-recognition machine that learns from examples!\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"avg_logprobs\": -0.31446178280821413\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 10,\n",
       "        \"candidates_token_count\": 638,\n",
       "        \"total_token_count\": 648,\n",
       "        \"prompt_tokens_details\": [\n",
       "          {\n",
       "            \"modality\": \"TEXT\",\n",
       "            \"token_count\": 10\n",
       "          }\n",
       "        ],\n",
       "        \"candidates_tokens_details\": [\n",
       "          {\n",
       "            \"modality\": \"TEXT\",\n",
       "            \"token_count\": 638\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"model_version\": \"gemini-2.0-flash\"\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
